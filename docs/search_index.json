[["sentiment.html", "1 Szótárak és érzelemelemzés 1.1 Fogalmi alapok 1.2 Szótárak az R-ben 1.3 A Magyar Nemzet elemzése 1.4 MNB sajtóközlemények", " 1 Szótárak és érzelemelemzés 1.1 Fogalmi alapok A szentiment- vagy vélemény-, illetve érzelemelemzés a számítógépes nyelvészet részterülete, melynek célja az egyes szövegek tartalmából kinyerni azokat az információkat, amelyek értékelést fejeznek ki.1 A véleményelemzés a szövegeket három szinten osztályozza. A legáltalánosabb a dokumentumszint osztályozás, amikor egy hosszabb szövegegység egészét vizsgáljuk, míg a mondatszint osztályozásnál a vizsgálat alapegysége a mondat. A legrészletesebb adatokat akkor nyerjük, amikor az elemzést target-szinten végezzük, azaz meghatározzuk azt is, hogy egy-egy érzelem a szövegen belül mire vonatkozik. Mindhárom szinten azonos a feladat: egyrészt meg kell állapítani, hogy az adott egységben van-e értékelés, vélemény vagy érzelem, és ha igen, akkor pedig meg kell határozni, hogy milyen azok érzelmi tartalma. A pozitív-negatív-semleges skálán mozgó szentimentelemzés mellett az elmúlt két évtizedben jelents lépések történtek a szövegek emóciótartalmának automatikus vizsgálatára is. A módszer hasonló a szentimentelemzéshez, tartalmilag azonban más skálán mozog. Az emócióelemzés esetén ugyanis nem csak azt kell meghatározni, hogy egy kifejezés pozitív vagy negatív töltettel rendelkezik, hanem azt is, hogy milyen érzelmet (öröm, bánat, undor stb.) hordoz. A szótár alapú szentiment- vagy emócióelemzés alapja az az egyszer ötlet, hogy ha tudjuk, hogy egyes szavak milyen érzelmeket, érzéseket hordoznak, akkor ezeket a szavakat egy szövegben megszámolva képet kaphatunk az adott dokumentum érzelmi tartalmáról. Mivel a szótár alapú elemzés az adott kategórián belüli kulcsszavak gyakoriságán alapul, ezért van, aki nem tekinti statisztikai elemzésnek (lásd például @young2012affective). A tágabb kvantitatív szövegelemzési kontextusban az osztályozáson (classification) belül a felügyelt módszerekhez hasonlóan itt is ismert kategóriákkal dolgozunk, azaz elre meghatározzuk, hogy egy-egy adott szó pozitív vagy negatív térték, vagy továbbmenve, milyen érzelmet hordoz, csak egyszerbb módszertannal [@grimmer2013text]. A kulcsszavakra építés miatt a módszer a kvalitatív és a kvantitatív kutatási vonalak találkozásának is tekinthet, hiszen egy-egy szónak az érzelmi töltete nem mindig ítélhet meg objektíven. Mint minden módszer esetében, itt is kiemelten fontos ellenrni, hogy a használt szótár kategóriák és kulcsszavak fedik-e a valóságot. Más szavakkal: validálás, validálás, validálás. A módszer elnyei: Tökéletesen megbízható: a számításoknak nincs probabilisztikus (azaz valószínségre épül) eleme, mint például a Support Vector alapú osztályozásnak, illetve az emberi szövegkódolásnál elforduló problémákat is elkerüljük (például azt, hogy két kódoló, vagy ugyanazon kódoló két különböz idpontban nem azonosan értékeli ugyanazt a kifejezést). Általa képesek vagyunk mérni a szöveg látens dimenzióit. Széles körben alkalmazható, egyszeren számolható. A politikatudományon és a számítógépes nyelvészeten belül nagyon sok kész szótár elérhet, amelyek különböz módszerekkel készültek és különböz területet fednek le (például populizmus, pártprogramok policy tartalma, érzelmek, gazdasági tartalom). Relatíve könnyen adaptálható egyik nyelvi környezetbl a másikba, bár szótárfordítások esetén külön hangsúlyt kell fektetni a validálásra.2 A módszer lehetséges hátrányai: A szótár hatékonysága és validitása azon múlik, hogy mennyire egyezik a szótár és a vizsgálni kívánt dokumentum területe. Nem mindegy például, hogy a szótárunkkal tzsdei jelentések alapján a gazdasági bizonytalanságot vagy nézk filmekre adott értékeléseit szeretnénk-e vizsgálni. Léteznek általános szentimentszótárak, ezek hatékonysága azonban általában alulmúlja a terület-specifikus szótárakét. A terület-specifikus szótár építése kvalitatív folyamat, éppen ezért id- és emberi erforrás igényes. A szózsák alapú elemzéseknél a kontextus elvész. Gondoljunk például a tagadásra: a nem vagyok boldog kifejezés esetén egy általános szentiment szótár a tagadás miatt félreosztályozná a mondat érzelmi töltését, hiszen a boldog szó önmagában a pozitív kategóriába tartozik. Természetesen az automatikus tagadás kezelésére is vannak lehetségek, de a kérdés komplexitása miatt ezek bemutatásától most eltekintünk. A legnagyobb méret általános szentimentszótár az angol nyelv SentiWordNet (SWN), ami kb. 150 000 szót tartalmaz, amelyek mindegyike a három szentimentérték  pozitív, negatív, semleges  közül kapott egyet.3[@baccianellaSentiwordnetEnhancedLexical2010] Az R-ben végzett szentimentelemzés során az angol nyelv szövegekhez több beépített általános szentimentszótár is a rendelkezésünkre áll.4 A teljesség igénye nélkül említhetjük az AFINN,5 a bing6 és az nrc7 szótárakat. Az elemzés sikere több faktortól is függ. Fontos, hogy a korpuszban lév dokumentumokat körültekinten tisztítsuk meg az elemzés elején (lásd a Korpuszépítés és elkészítés fejezetet). A következ lépésben meg kell bizonyosodnunk arról, hogy a kiválasztott szentiment szótár alkalmazható a korpuszunkra. Amennyiben nem találunk alkalmas szótárt, akkor a saját szótár validálására kell figyelni. A negyedik fejezetben leírtak itt is érvényesek, a dokumentum-kifejezés mátrixot érdemes valamilyen módon súlyozni. 1.2 Szótárak az R-ben A szótár alapú elemzéshez a quanteda csomagot fogjuk használni, illetve a 3. fejezetben már megismert readr, stringr, dplyr tidyverse csomagokat.8 library(stringr) library(dplyr) library(tidyr) library(ggplot2) library(quanteda) library(HunMineR) library(plotly) Mieltt két esettanulmányt bemutatnánk, vizsgáljuk meg, hogyan néz ki egy szentimentszótár az R-ben. A szótárt kézzel úgy tudjuk elkészíteni, hogy egy listán belül létrehozzuk karaktervektorként a kategóriákat és a kulcsszavakat, és ezt a listát a quanteda dictionary függvényével eltároljuk. szentiment_szotar &lt;- dictionary( list( pozitiv = c(&quot;jó&quot;, &quot;boldog&quot;, &quot;öröm&quot;), negativ = c(&quot;rossz&quot;, &quot;szomorú&quot;, &quot;lehangoló&quot;) ) ) szentiment_szotar #&gt; Dictionary object with 2 key entries. #&gt; - [pozitiv]: #&gt; - jó, boldog, öröm #&gt; - [negativ]: #&gt; - rossz, szomorú, lehangoló A quanteda, quanteda.corpora és tidytext R csomagok több széles körben használt szentiment szótárat tartalmaznak, így nem kell kézzel replikálni minden egyes szótárat, amit használni szeretnénk. A szentiment elemzési munkafolyamat, amit ebben a részfejezetben bemutatunk, a következ lépésekbl áll: dokumentumok betöltése, szöveg elkészítése, a korpusz létrehozása, dokumentum-kifejezés mátrix létrehozása, szótár betöltése, a dokumentum-kifejezés mátrix szrése a szótárban lév kulcsszavakkal, az eredmény vizualizálása, további felhasználása. A fejezetben két különböz korpuszt fogunk elemezni: a 2006-os Magyar Nemzet címlapjainak egy 252 cikkbl álló mintáját vizsgáljuk egy magyar szentiment szótárral.9 A második korpusz a Magyar Nemzeti Bank angol nyelv sajtóközleményeibl áll, amin egy széles körben használt gazdasági szótár használatát mutatjuk be.10 1.3 A Magyar Nemzet elemzése mn_minta &lt;- HunMineR::data_magyar_nemzet_small A HunMineR csomag segítségével beolvassuk a Magyar Nemzet adatbázis egy kisebb részét, ami az esetünkben a 2006-os címlapokon szerepl híreket jelenti. A summary() parancs, ahogy a neve is mutatja, gyors áttekintést nyújt a betöltött adatbázisról. Látjuk, hogy 2834 sorból (megfigyelés) és 3 oszlopból (változó) áll. Els ránézésre látszik, hogy a text változónk tartalmazza a szövegeket, és hogy azok tisztításra szorulnak. glimpse(mn_minta) #&gt; Rows: 2,834 #&gt; Columns: 3 #&gt; $ doc_id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 3~ #&gt; $ text &lt;chr&gt; &quot;Hat fovárosi képviselo öt percnél is kevesebbet beszélt egy év alatt a közgyulésben.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n&quot;, &quot;Moszkva elzárta a~ #&gt; $ doc_date &lt;date&gt; 2006-01-02, 2006-01-02, 2006-01-02, 2006-01-02, 2006-01-02, 2006-01-02, 2006-01-02, 2006-01-02, 2006-01-02, 2006-01-02, 2006-01~ A glimpse függvény segítségével belepillanthatunk a használt corpusba és láthatjuk, hogy az 3 oszlopból áll a dokumentum azonosítójából, amely csak egy sorszám, a dokumentum szövegébl, és a dokumentumhoz tartozó azonosítóból. Az els szöveget megnézve látjuk, hogy a standard elkészítési lépések mellett a sortörést (\\n) is ki kell törölnünk. mn_minta$text[1] #&gt; [1] &quot;Hat fovárosi képviselo öt percnél is kevesebbet beszélt egy év alatt a közgyulésben.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n&quot; Habár a quanteda is lehetséget ad néhány elkészít lépésre, érdemes ezt olyan céleszközzel tenni, ami nagyobb rugalmasságot ad a kezünkbe. Mi erre a célra a stringr csomagot használjuk. Els lépésben kitöröljük a sortöréseket (\\n), a központozást, a számokat és kisbetsítünk minden szót. Elfordulhat, hogy (számunkra nehezen látható) extra szóközök maradnak a szövegben. Ezeket az str_squish()függvénnyel tüntetjük el. A szöveg eleji és végi extra szóközöket (leading vagy trailing white space) az str_trim() függvény vágja le. mn_tiszta &lt;- mn_minta %&gt;% mutate( text = stringr::str_remove_all(string = text, pattern = &quot;\\n&quot;), text = stringr::str_remove_all(string = text, pattern = &quot;[:punct:]&quot;), text = stringr::str_remove_all(string = text, pattern = &quot;[:digit:]&quot;), text = stringr::str_to_lower(text), text = stringr::str_trim(text), text = stringr::str_squish(text) ) A szöveg sokkal jobban néz ki, habár észrevehetjük, hogy maradhattak benne problémás részek, fleg a sortörés miatt, ami sajnos hol egyes szavak közepén van (a jobbik eset), vagy pedig pont szóhatáron, ez esetben a két szó sajnos összevonódik. Az egyszerség kedvéért feltételezzük, hogy ez kellen ritkán fordul el ahhoz, hogy ne befolyásolja az elemzésünk eredményét. mn_tiszta$text[1] #&gt; [1] &quot;hat fovárosi képviselo öt percnél is kevesebbet beszélt egy év alatt a közgyulésben&quot; Miután kész a tisztá(bb) szövegünk, korpuszt hozunk létre a quanteda corpus() függvényével. A corpus objektum a szöveg mellett egyéb dokumentum meta adatokat is tud tárolni (dátum, író, hely, stb.) Ezeket mi is hozzáadhatjuk (erre majd látunk példát), illetve amikor létrehozzuk a korpuszt a data frame-ünkbl, automatikusan metaadatokként tárolódnak a változóink. Jelen esetben az egyetlen dokumentum változónk a szöveg mellett a dátum lesz. A korpusz dokumentum változóihoz a docvars() függvény segítségével tudunk hozzáférni. mn_corpus &lt;- corpus(mn_tiszta) head(docvars(mn_corpus), 5) #&gt; doc_date #&gt; 1 2006-01-02 #&gt; 2 2006-01-02 #&gt; 3 2006-01-02 #&gt; 4 2006-01-02 #&gt; 5 2006-01-02 A következ lépés a dokumentum-kifejezés mátrix létrehozása a dfm() függvénnyel. Elször tokenekre bontjuk a szövegeket a tokens() paranccsal, és aztán ezt a tokenizált szózsákot kapja meg a dfm inputnak. A sor a végén a létrehozott mátrixunkat TF-IDF módszerrel súlyozzuk a dfm_tfidf() függvény használatával. mn_dfm &lt;- mn_corpus %&gt;% tokens(what = &quot;word&quot;) %&gt;% dfm() %&gt;% dfm_tfidf() A cikkek szentimentjét egy magyar szótárral fogjuk becsülni, amit a Társadalomtudományi Kutatóközpont kutatói a Mesterséges Intelligencia Nemzeti Laboratórium projekt keretében készítettek.11 Két dimenziót tarlamaz (pozitív és negatív), 2614 pozitív és 2654 negatív kulcsszóval. Ez nem számít kirívóan nagynak a szótárak között, mivel az adott kategóriák minél teljesebb lefedése a cél. poltext_szotar &lt;- HunMineR::dictionary_poltext poltext_szotar #&gt; Dictionary object with 2 key entries. #&gt; - [positive]: #&gt; - abszolút, ad, adaptív, adekvát, adócsökkentés, adókedvezmény, adomány, adományoz, adóreform, adottság, adottságú, áfacsökkentés, agilis, agytröszt, áhított, ajándék, ajándékoz, ajánl, ajánlott, akadálytalan [ ... and 2,279 more ] #&gt; - [negative]: #&gt; - aberrált, abnormális, abnormalitás, abszurd, abszurditás, ádáz, adócsalás, adócsaló, adós, adósság, áfacsalás, áfacsaló, affér, aggasztó, aggodalom, aggódik, aggódás, agresszió, agresszíven, agresszivitás [ ... and 2,568 more ] Az egyes dokumentumok szentimentjét a dfm_lookup() becsüli, ahol az elz lépésben létrehozott súlyozott dfm az input és a magyar szentimentszótár a dictionary. Egy gyors pillantás az eredményre és látjuk hogy minden dokumentumhoz készült egy pozitív és egy negatív érték. A TF-IDF súlyozás miatt nem látunk egész számokat (a súlyozás nélkül a sima szófrekvenciát kapnánk). mn_szentiment &lt;- quanteda::dfm_lookup(mn_dfm, dictionary = poltext_szotar) head(mn_szentiment, 5) #&gt; Document-feature matrix of: 5 documents, 2 features (40.00% sparse) and 1 docvar. #&gt; features #&gt; docs positive negative #&gt; 1 0 0 #&gt; 2 0.838 12.50 #&gt; 3 0 0 #&gt; 4 21.104 6.45 #&gt; 5 11.036 8.13 Ahhoz, hogy fel tudjuk használni a kapott eredményt, érdemes dokumentumváltozóként eltárolni a korpuszban. Ezt a fent már használt docvars() függvény segítségével tudjuk megtenni, ahol a második argumentumként az új változó nevét adjuk meg. docvars(mn_corpus, &quot;pos&quot;) &lt;- as.numeric(mn_szentiment[, 1]) docvars(mn_corpus, &quot;neg&quot;) &lt;- as.numeric(mn_szentiment[, 2]) head(docvars(mn_corpus), 5) #&gt; doc_date pos neg #&gt; 1 2006-01-02 0.000 0.00 #&gt; 2 2006-01-02 0.838 12.50 #&gt; 3 2006-01-02 0.000 0.00 #&gt; 4 2006-01-02 21.104 6.45 #&gt; 5 2006-01-02 11.036 8.13 Végül a kapott korpuszt a kiszámolt szentimentértékekkel a quanteda-ban lév convert() függvénnyel adattáblává alakítjuk. Aconvert() függvény dokumentációját érdemes elolvasni, mert ennek segítségével tudjuk a quanteda-ban elkészült objektumainkat átalakítani úgy, hogy azt más csomagok is tudják használni. mn_df &lt;- quanteda::convert(mn_corpus, to = &quot;data.frame&quot;) Mieltt vizualizálnánk az eredményt érdemes a napi szintre aggregálni a szentimentértéket és egy nettó értéket kalkulálni (ld. 1.1. ábra).12 mn_df &lt;- mn_df %&gt;% group_by(doc_date) %&gt;% summarise( daily_pos = sum(pos), daily_neg = sum(neg), net_daily = daily_pos - daily_neg ) Az így kapott plot y tengelyén az adott cikkek idpontját láthatjuk, míg az x tengelyén a szentiment értékeiket. Ebben több kiugrást is tapasztalhatunk. Természetesen messzemen következtetéseket egy ilyen kis korpusz alapján nem vonhatunk le, de a kiugrásokhoz tartozó cikkek kvalitatív vizsgálatával megállapíthatjuk, hogy az áprilisi kiugrást a választásokhoz kötd cikkek pozitív hangulata, míg az októberi negatív kilengést az öszödi beszéd nyilvánosságra kerüléséhez köthet cikkek negatív szentimentje okozza. mncim_df &lt;- ggplot(mn_df, aes(doc_date, net_daily)) + geom_line() + labs( y = &quot;Szentiment&quot;, x = NULL, caption = &quot;Adatforrás: https://cap.tk.hu/&quot; ) ggplotly(mncim_df) Ábra 1.1: Magyar Nemzet címlap szentimentje 1.4 MNB sajtóközlemények A második esettanulmányban a kontextuális szótárelemzést mutatjuk be egy angol nyelv korpusz és specializált szótár segítségével. A korpusz az MNB kamatdöntéseit kísér nemzetközi sajtóközleményei, a szótár pedig a @loughranWhenLiabilityNot2011 pénzügyi szentimentszótár.13 penzugy_szentiment &lt;- HunMineR::dictionary_LoughranMcDonald penzugy_szentiment #&gt; Dictionary object with 9 key entries. #&gt; - [NEGATIVE]: #&gt; - abandon, abandoned, abandoning, abandonment, abandonments, abandons, abdicated, abdicates, abdicating, abdication, abdications, aberrant, aberration, aberrational, aberrations, abetting, abnormal, abnormalities, abnormality, abnormally [ ... and 2,335 more ] #&gt; - [POSITIVE]: #&gt; - able, abundance, abundant, acclaimed, accomplish, accomplished, accomplishes, accomplishing, accomplishment, accomplishments, achieve, achieved, achievement, achievements, achieves, achieving, adequately, advancement, advancements, advances [ ... and 334 more ] #&gt; - [UNCERTAINTY]: #&gt; - abeyance, abeyances, almost, alteration, alterations, ambiguities, ambiguity, ambiguous, anomalies, anomalous, anomalously, anomaly, anticipate, anticipated, anticipates, anticipating, anticipation, anticipations, apparent, apparently [ ... and 277 more ] #&gt; - [LITIGIOUS]: #&gt; - abovementioned, abrogate, abrogated, abrogates, abrogating, abrogation, abrogations, absolve, absolved, absolves, absolving, accession, accessions, acquirees, acquirors, acquit, acquits, acquittal, acquittals, acquittance [ ... and 883 more ] #&gt; - [CONSTRAINING]: #&gt; - abide, abiding, bound, bounded, commit, commitment, commitments, commits, committed, committing, compel, compelled, compelling, compels, comply, compulsion, compulsory, confine, confined, confinement [ ... and 164 more ] #&gt; - [SUPERFLUOUS]: #&gt; - aegis, amorphous, anticipatory, appertaining, assimilate, assimilating, assimilation, bifurcated, bifurcation, cessions, cognizable, concomitant, correlative, deconsolidation, delineation, demonstrable, demonstrably, derecognized, derecognizes, derivatively [ ... and 36 more ] #&gt; [ reached max_nkey ... 3 more keys ] A szentimentszótár 9 kategóriából áll. A legtöbb kulcsszó a negatív dimenzióhoz van (2355). A munkamenet hasonló az elz példához: adat betöltés, szövegtisztítás, korpusz létrehozás, tokenizálás, kulcs kontextuális tokenek szrése, dfm elállítás és szentiment számítás, az eredmény vizualizálása, további felhasználása. mnb_pr &lt;- HunMineR::data_mnb_pr Adatbázisunk 180 megfigyelésbl és 4 változóból áll. Az egyetlen lényeges dokumentum metaadat itt is a szövegek megjelenési ideje, de a glimpse függvénnyel itt is ellenrizhetjük hogyan néz ki a corpus felépítése és milyen metaadatokat tartalmaz pontosan. glimpse(mnb_pr) #&gt; Rows: 180 #&gt; Columns: 4 #&gt; $ date &lt;date&gt; 2005-01-24, 2005-02-21, 2005-03-29, 2005-04-25, 2005-05-23, 2005-06-20, 2005-07-18, 2005-08-22, 2005-09-19, 2005-10-24, 2005-11-28,~ #&gt; $ text &lt;chr&gt; &quot;At its meeting on January the Monetary Council considered the latest economic and financial developments and decided to reduce the ~ #&gt; $ id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 3~ #&gt; $ year &lt;dbl&gt; 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, ~ Ez alapján pedig láthatjuk, hogy a corpus a tényleges szövegek mellett tartalmaz még id sorszámot, pontos dátumot és évet is. A szövegeket ugyanazokkal a standard eszközökkel kezeljük, mint a Magyar Nemzet esetében. Érdemes minden esetben ellenrizni, hogy az R-kód, amit használunk, tényleg azt csinálja-e, amit szeretnénk. Ez hatványozottan igaz abban az esetben, amikor szövegekkel és reguláris kifejezésekkel dolgozunk. mnb_tiszta &lt;- mnb_pr %&gt;% mutate( text = str_remove_all(string = text, pattern = &quot;[:cntrl:]&quot;), text = str_remove_all(string = text, pattern = &quot;[:punct:]&quot;), text = str_remove_all(string = text, pattern = &quot;[:digit:]&quot;), text = str_to_lower(text), text = str_trim(text), text = str_squish(text) ) Miután rendelkezésre állnak a tiszta dokumentumaink, egy karaktervektorba gyjtjük azokat a kulcsszavakat, amelyek környékén szeretnénk megfigyelni a szentiment alakulását. A példa kedvéért mi az unemp*, growth, gdp, inflation* szótöveket és szavakat választottuk. A tokens_keep() megtartja a kulcsszavainkat és egy általunk megadott +/- n tokenes környezetüket (jelen esetben 10). A szentimentelemzést pedig már ezen a jóval kisebb mátrixon fogjuk lefuttatni. A phrase() segítségével több szóból álló kifejezéséket is vizsgálhatunk. Ilyen szókapcsolat például az Európai Unió\" is, ahol lényeges, hogy egyben kezeljük a két szót. mnb_corpus &lt;- corpus(mnb_tiszta) gazdasag &lt;- c(&quot;unemp*&quot;, &quot;growth&quot;, &quot;gdp&quot;, &quot;inflation*&quot;, &quot;inflation expectation*&quot;) mnb_token &lt;- tokens(mnb_corpus) %&gt;% tokens_keep(pattern = phrase(gazdasag), window = 10) A szentimentet most is egy súlyozott dfm-bl számoljuk. A kész eredményt hozzáadjuk a korpuszhoz, majd adattáblát hozunk létre belle. A 9 kategóriából 5-öt használunk csak, amelyeknek jegybanki környezetben értelmezhet tartalma van. mnb_szentiment &lt;- tokens_lookup(mnb_token, dictionary = penzugy_szentiment) %&gt;% dfm() %&gt;% dfm_tfidf() docvars(mnb_corpus, &quot;negative&quot;) &lt;- as.numeric(mnb_szentiment[, &quot;negative&quot;]) docvars(mnb_corpus, &quot;positive&quot;) &lt;- as.numeric(mnb_szentiment[, &quot;positive&quot;]) docvars(mnb_corpus, &quot;uncertainty&quot;) &lt;- as.numeric(mnb_szentiment[, &quot;uncertainty&quot;]) docvars(mnb_corpus, &quot;constraining&quot;) &lt;- as.numeric(mnb_szentiment[, &quot;constraining&quot;]) docvars(mnb_corpus, &quot;superfluous&quot;) &lt;- as.numeric(mnb_szentiment[, &quot;superfluous&quot;]) mnb_df &lt;- convert(mnb_corpus, to = &quot;data.frame&quot;) A célunk, hogy szentiment kategóriánkénti bontásban mutassuk be az elemzésünk eredményét, de eltte egy kicsit alakítani kell az adattáblán, hogy a korábban már tárgyalt tidy formára hozzuk. A különböz szentiment értékeket tartalmazó oszlopokat fogjuk átrendezni úgy, hogy kreálunk egy sent_type változót, ahol a kategória nevet fogjuk eltárolni és egy sent_score változót, ahol a szentiment értéket. Ehhez a tidyr-ben található pivot_longer() föggvényt használjuk. mnb_df &lt;- mnb_df %&gt;% tidyr::pivot_longer( cols = negative:superfluous, names_to = &quot;sent_type&quot;, values_to = &quot;sent_score&quot; ) Az átalakítás után már könnyedén tudjuk kategóriákra bontva megjeleníteni az MNB közlemények különböz látens dimenzióit. Fontos emlékezni arra, hogy ez az eredmény a kulcsszavaink +/- 10 tokenes környezetében lév szavak szentimentjét méri. Az így kapott ábránk a három alkalmazott szentiment kategória idbeli elfordulását mutatja be. Ami érdekes eredmény, hogy a felesleges töltelék (superfluous) szövegek szinte soha nem fordulnak el a kulcsszavaink körül. A többi érték is nagyjából megfelel a várakozásainknak, habár a 2008-as gazdasági válság nem tnik kiugró pontnak. Azonban a 2010 utáni európai válság már láthatóan megjelenik az idsorainkban (ld. 1.2. ábra). Az általunk használt szótár alapveten az Egyesült Államokban a tzsdén keresked cégek publikus beszámolóiból készült, így elképzelhet, hogy egyes jegybanki környezetben sokat használt kifejezések nincsenek benne. A kapott eredmények validálása ezért is nagyon fontos, illetve érdemes azzal is tisztában lenni, hogy a szótáras módszer nem tökéletes (ahogy az emberi vagy más gépi kódolás sem). mnsent_df &lt;- ggplot(mnb_df, aes(date, sent_score)) + geom_line() + labs( y = NULL, x = NULL ) + facet_wrap(~sent_type, ncol = 1)+ theme(panel.spacing = unit(2, &quot;lines&quot;)) ggplotly(mnsent_df) Ábra 1.2: Magyar Nemzeti Bank közleményeinek szentimentje Bvebben lásd például: [@liuSentimentAnalysisSubjectivity2010] A lehetséges, területspecifikus szótáralkotási módszerekrl részletesebben ezekben a tanulmányokban lehet olvasni: @laver2000estimating; @young2012affective; @loughranWhenLiabilityNot2011; @mateEffectCentralBank2021 A szótár és dokumentációja elérhet az alábbi linken: https://github.com/aesuli/SentiWordNet A quanteda.dictionaries csomag leírása és a benne található szótárak az alábbi github linken érhetek el: https://github.com/kbenoit/quanteda.dictionaries A szótár és dokumentációja elérhet itt: http://www2.imm.dtu.dk/pubdb/pubs/6010-full.html A szótár és dokumentációja elérhet itt: https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html A szótár és dokumentációja elérhet itt: http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm A szentimentelemzéshez gyakran használt csomag még a tidytext. A szerzk online is szabadon elérhet könyvük @silge2017text 2. fejezetében részletesen is bemutatják a tidytext munkafolyamatot: (https://www.tidytextmining.com/sentiment.html). A korpusz a Hungarian Compartive Agendas Project keretében készült és regisztáció után, kutatási célra elérhet az alábbi linken: https://cap.tk.hu/a-media-es-a-kozvelemeny-napirendje. A korpusz, a szótár és az elemzés teljes dokumentációja elérhet az alábbi github linken: https://github.com/poltextlab/central_bank_communication, a teljes elemzés [@mateEffectCentralBank2021] elérhet: https://doi.org/10.1371/journal.pone.0245515 ELKH TK MILAB: https://milab.tk.hu/hu A szótár és a hozzátartozó dokumentáció elérhet az alábbi github oldalon: https://github.com/poltextlab/sentiment_hun A csoportosított adatokkal való munka bvebb bemutatását lásd a Függelékben. A témával részletesen foglalkozó tanulmányban egy saját monetáris szentimentszótárat mutatunk be: Az implementáció és a hozzá tartozó R forráskód nyilvános: https://doi.org/10.6084/m9.figshare.13526156.v1 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
